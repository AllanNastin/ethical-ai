{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T09:36:34.521353Z",
     "start_time": "2024-03-12T09:36:32.665273Z"
    }
   },
   "id": "a989eb1ff66e9813",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['INTRODUCTION  The  Commission  adopted  the  proposal  for  a  Regulation  laying  down  harmonised  rules  on  artificial intelligence (Artificial Intelligence Act, hereinafter',\n 'the AI Act) on 21 April 2021',\n 'The  Council  unanimously  adopted  its  General  Approach  on  the  proposal  on  6  December  2022, while the European Parliament (hereinafter',\n 'the EP) confirmed its position in a plenary  vote on 14 June 2023',\n 'On 14 June 2023, 18 July 2023, 2-3 October 2023 and 24 October 2023 the first four political  trilogues  were  held,  during  which  some  of  the  less  controversial  parts  of  the  proposal  were  agreed and compromise was also found on the provisions concerning measures in support of  innovation,  as  well  as  and  on  the  mechanism  for  classification  of  AI  systems  as  high-risk']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the AI Act\n",
    "with open(\"ai_act/ai-act.txt\", \"r\") as file:\n",
    "    ai_act = file.read()\n",
    "\n",
    "# Split the AI Act into sentences\n",
    "ai_act = ai_act.replace(\"\\n\", \" \")\n",
    "sentences = re.split(r'[.;:]', ai_act)\n",
    "sentences = [s.strip() for s in sentences if len(s.strip()) > 7]\n",
    "sentences[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T18:02:27.146369Z",
     "start_time": "2024-03-11T18:02:27.129350Z"
    }
   },
   "id": "f462def6f1a1f7fb",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "`sentences` is a list of strings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8983db8dbd828f0d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-large-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "[[{'entity': 'B-PER',\n   'score': 0.9971501,\n   'index': 4,\n   'word': 'Wolfgang',\n   'start': 11,\n   'end': 19},\n  {'entity': 'B-LOC',\n   'score': 0.9986046,\n   'index': 9,\n   'word': 'Berlin',\n   'start': 34,\n   'end': 40}],\n [{'entity': 'B-PER',\n   'score': 0.99836797,\n   'index': 4,\n   'word': 'Dylan',\n   'start': 11,\n   'end': 16},\n  {'entity': 'B-LOC',\n   'score': 0.9990356,\n   'index': 9,\n   'word': 'Dublin',\n   'start': 31,\n   'end': 37}]]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-large-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-large-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "examples = [\"My name is Wolfgang and I live in Berlin\",\n",
    "            \"My name is Dylan and I live in Dublin\"]\n",
    "\n",
    "\n",
    "ner_results = nlp(examples)\n",
    "ner_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T09:36:38.966012Z",
     "start_time": "2024-03-12T09:36:36.617814Z"
    }
   },
   "id": "1c8190e4a06aebe6",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[['My', 'name', 'is', 'Wolfgang', 'and', 'I', 'live', 'in', 'Berlin'],\n ['My', 'name', 'is', 'Dylan', 'and', 'I', 'live', 'in', 'Dublin']]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [sentences.split() for sentences in examples]\n",
    "tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T09:36:46.340495Z",
     "start_time": "2024-03-12T09:36:46.335761Z"
    }
   },
   "id": "e859cfd6a84c8cef",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "`ner_results` has an outer list (containing each sentence). Each sentence is itself a list of entities. Each entity is represented as a dictionary."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82e1d26cfeb83b0d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "docred = load_dataset(\"docred\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T18:44:00.950488Z",
     "start_time": "2024-03-11T18:43:58.691577Z"
    }
   },
   "id": "da8f66afeb74b672",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'title': 'AirAsia Zest',\n 'sents': [['Zest',\n   'Airways',\n   ',',\n   'Inc.',\n   'operated',\n   'as',\n   'AirAsia',\n   'Zest',\n   '(',\n   'formerly',\n   'Asian',\n   'Spirit',\n   'and',\n   'Zest',\n   'Air',\n   ')',\n   ',',\n   'was',\n   'a',\n   'low',\n   '-',\n   'cost',\n   'airline',\n   'based',\n   'at',\n   'the',\n   'Ninoy',\n   'Aquino',\n   'International',\n   'Airport',\n   'in',\n   'Pasay',\n   'City',\n   ',',\n   'Metro',\n   'Manila',\n   'in',\n   'the',\n   'Philippines',\n   '.'],\n  ['It',\n   'operated',\n   'scheduled',\n   'domestic',\n   'and',\n   'international',\n   'tourist',\n   'services',\n   ',',\n   'mainly',\n   'feeder',\n   'services',\n   'linking',\n   'Manila',\n   'and',\n   'Cebu',\n   'with',\n   '24',\n   'domestic',\n   'destinations',\n   'in',\n   'support',\n   'of',\n   'the',\n   'trunk',\n   'route',\n   'operations',\n   'of',\n   'other',\n   'airlines',\n   '.'],\n  ['In',\n   '2013',\n   ',',\n   'the',\n   'airline',\n   'became',\n   'an',\n   'affiliate',\n   'of',\n   'Philippines',\n   'AirAsia',\n   'operating',\n   'their',\n   'brand',\n   'separately',\n   '.'],\n  ['Its',\n   'main',\n   'base',\n   'was',\n   'Ninoy',\n   'Aquino',\n   'International',\n   'Airport',\n   ',',\n   'Manila',\n   '.'],\n  ['The',\n   'airline',\n   'was',\n   'founded',\n   'as',\n   'Asian',\n   'Spirit',\n   ',',\n   'the',\n   'first',\n   'airline',\n   'in',\n   'the',\n   'Philippines',\n   'to',\n   'be',\n   'run',\n   'as',\n   'a',\n   'cooperative',\n   '.'],\n  ['On',\n   'August',\n   '16',\n   ',',\n   '2013',\n   ',',\n   'the',\n   'Civil',\n   'Aviation',\n   'Authority',\n   'of',\n   'the',\n   'Philippines',\n   '(',\n   'CAAP',\n   ')',\n   ',',\n   'the',\n   'regulating',\n   'body',\n   'of',\n   'the',\n   'Government',\n   'of',\n   'the',\n   'Republic',\n   'of',\n   'the',\n   'Philippines',\n   'for',\n   'civil',\n   'aviation',\n   ',',\n   'suspended',\n   'Zest',\n   'Air',\n   'flights',\n   'until',\n   'further',\n   'notice',\n   'because',\n   'of',\n   'safety',\n   'issues',\n   '.'],\n  ['Less',\n   'than',\n   'a',\n   'year',\n   'after',\n   'AirAsia',\n   'and',\n   'Zest',\n   'Air',\n   \"'s\",\n   'strategic',\n   'alliance',\n   ',',\n   'the',\n   'airline',\n   'has',\n   'been',\n   'rebranded',\n   'as',\n   'AirAsia',\n   'Zest',\n   '.'],\n  ['The',\n   'airline',\n   'was',\n   'merged',\n   'into',\n   'AirAsia',\n   'Philippines',\n   'in',\n   'January',\n   '2016',\n   '.']],\n 'vertexSet': [[{'name': 'Zest Airways, Inc.',\n    'sent_id': 0,\n    'pos': [0, 4],\n    'type': 'ORG'},\n   {'name': 'Asian Spirit and Zest Air',\n    'sent_id': 0,\n    'pos': [10, 15],\n    'type': 'ORG'},\n   {'name': 'AirAsia Zest', 'sent_id': 0, 'pos': [6, 8], 'type': 'ORG'},\n   {'name': 'AirAsia Zest', 'sent_id': 6, 'pos': [19, 21], 'type': 'ORG'}],\n  [{'name': 'Ninoy Aquino International Airport',\n    'sent_id': 3,\n    'pos': [4, 8],\n    'type': 'LOC'},\n   {'name': 'Ninoy Aquino International Airport',\n    'sent_id': 0,\n    'pos': [26, 30],\n    'type': 'LOC'}],\n  [{'name': 'Pasay City', 'sent_id': 0, 'pos': [31, 33], 'type': 'LOC'}],\n  [{'name': 'Metro Manila', 'sent_id': 0, 'pos': [34, 36], 'type': 'LOC'}],\n  [{'name': 'Philippines', 'sent_id': 0, 'pos': [38, 39], 'type': 'LOC'},\n   {'name': 'Philippines', 'sent_id': 4, 'pos': [13, 14], 'type': 'LOC'},\n   {'name': 'Republic of the Philippines',\n    'sent_id': 5,\n    'pos': [25, 29],\n    'type': 'LOC'}],\n  [{'name': 'Manila', 'sent_id': 1, 'pos': [13, 14], 'type': 'LOC'},\n   {'name': 'Manila', 'sent_id': 3, 'pos': [9, 10], 'type': 'LOC'}],\n  [{'name': 'Cebu', 'sent_id': 1, 'pos': [15, 16], 'type': 'LOC'}],\n  [{'name': '24', 'sent_id': 1, 'pos': [17, 18], 'type': 'NUM'}],\n  [{'name': '2013', 'sent_id': 2, 'pos': [1, 2], 'type': 'TIME'},\n   {'name': 'August 16, 2013', 'sent_id': 5, 'pos': [1, 5], 'type': 'TIME'}],\n  [{'name': 'Philippines AirAsia',\n    'sent_id': 2,\n    'pos': [9, 11],\n    'type': 'ORG'}],\n  [{'name': 'Asian Spirit', 'sent_id': 4, 'pos': [5, 7], 'type': 'ORG'}],\n  [{'name': 'Civil Aviation Authority of the Philippines',\n    'sent_id': 5,\n    'pos': [7, 13],\n    'type': 'ORG'},\n   {'name': 'CAAP', 'sent_id': 5, 'pos': [14, 15], 'type': 'ORG'}],\n  [{'name': 'Zest Air', 'sent_id': 5, 'pos': [34, 36], 'type': 'ORG'},\n   {'name': 'Zest Air', 'sent_id': 6, 'pos': [7, 9], 'type': 'ORG'}],\n  [{'name': 'a year', 'sent_id': 6, 'pos': [2, 4], 'type': 'NUM'}],\n  [{'name': 'AirAsia', 'sent_id': 6, 'pos': [5, 6], 'type': 'ORG'}],\n  [{'name': 'AirAsia Philippines',\n    'sent_id': 7,\n    'pos': [5, 7],\n    'type': 'ORG'}],\n  [{'name': 'January 2016', 'sent_id': 7, 'pos': [8, 10], 'type': 'TIME'}]],\n 'labels': {'head': [0, 0, 12, 2, 2, 4, 5, 3, 3, 3, 1, 1, 10],\n  'tail': [2, 4, 4, 4, 3, 3, 4, 2, 4, 4, 2, 4, 4],\n  'relation_id': ['P159',\n   'P17',\n   'P17',\n   'P17',\n   'P131',\n   'P150',\n   'P17',\n   'P150',\n   'P131',\n   'P17',\n   'P131',\n   'P17',\n   'P17'],\n  'relation_text': ['headquarters location',\n   'country',\n   'country',\n   'country',\n   'located in the administrative territorial entity',\n   'contains administrative territorial entity',\n   'country',\n   'contains administrative territorial entity',\n   'located in the administrative territorial entity',\n   'country',\n   'located in the administrative territorial entity',\n   'country',\n   'country'],\n  'evidence': [[0],\n   [2, 4, 7],\n   [6, 7],\n   [0],\n   [0],\n   [0],\n   [0, 3],\n   [0],\n   [0, 3],\n   [0, 3],\n   [0, 3],\n   [0, 3],\n   [4]]}}"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docred[\"train_annotated\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:53:17.380903Z",
     "start_time": "2024-03-11T19:53:17.348481Z"
    }
   },
   "id": "d9003a3ec12e07c3",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DocRED Format\n",
    "Each element is a dictionary with the following keys:\n",
    "- `title`: A short (few word) summary of the passage\n",
    "- `sents`: A list of sentences (list of lists of words, where a sentence is a list of words)\n",
    "- `vertexSet`: A list of entities, each entity has a list of its appearances in the passage (represented as a dictionary)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9e485f3d19aa296"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'title': 'Legal text about AI',\n  'sents': [['My',\n    'name',\n    'is',\n    'Wolfgang',\n    'and',\n    'I',\n    'live',\n    'in',\n    'Berlin']],\n  'vertexSet': [[{'name': 'Wolfgang',\n     'sent_id': 0,\n     'pos': [11, 12],\n     'type': 'PER'}],\n   [{'name': 'Berlin', 'sent_id': 0, 'pos': [34, 35], 'type': 'LOC'}]],\n  'labels': {'head': [],\n   'tail': [],\n   'relation_id': [],\n   'relation_text': [],\n   'evidence': []}},\n {'title': 'Legal text about AI',\n  'sents': [['My', 'name', 'is', 'Dylan', 'and', 'I', 'live', 'in', 'Dublin']],\n  'vertexSet': [[{'name': 'Dylan',\n     'sent_id': 0,\n     'pos': [11, 12],\n     'type': 'PER'}],\n   [{'name': 'Dublin', 'sent_id': 0, 'pos': [31, 32], 'type': 'LOC'}]],\n  'labels': {'head': [],\n   'tail': [],\n   'relation_id': [],\n   'relation_text': [],\n   'evidence': []}}]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Fix multi-word entities\n",
    "\n",
    "def fix_labels(my_str):\n",
    "    if my_str == \"I-LOC\" or my_str == \"B-LOC\":\n",
    "        return \"LOC\"\n",
    "    if my_str == \"I-ORG\" or my_str == \"B-ORG\":\n",
    "        return \"ORG\"\n",
    "    if my_str == \"I-PER\" or my_str == \"B-PER\":\n",
    "        return \"PER\"\n",
    "    return \"MISC\"\n",
    "\n",
    "\n",
    "ner_json_format = [\n",
    "    {\"title\": \"Legal text about AI\", \n",
    "     \"sents\": [tokens[i]], \n",
    "     \"vertexSet\": [[{\n",
    "         \"name\": entity[\"word\"], \n",
    "         \"sent_id\": 0, \n",
    "         \"pos\": [entity[\"start\"], entity[\"start\"] + len(entity[\"word\"].split())], \n",
    "         \"type\": fix_labels(entity[\"entity\"])}] for entity in ner_results[i]],\n",
    "     \"labels\": {\"head\": [], \"tail\": [], \"relation_id\": [], \"relation_text\": [], \"evidence\": []}} for i in range(len(examples))]\n",
    "ner_json_format"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T09:55:48.176739Z",
     "start_time": "2024-03-12T09:55:48.167131Z"
    }
   },
   "id": "e57fed3f73800115",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"ner_output.json\", 'w') as file:\n",
    "    json.dump(ner_json_format, file, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T20:30:02.313899Z",
     "start_time": "2024-03-11T20:30:02.297928Z"
    }
   },
   "id": "cbbda2984d866ed7",
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
